# ðŸ¤– Intelligente Daten-Ingestion - Komplette ErklÃ¤rung

**Datum**: 2026-01-28
**Status**: âœ… **Produktiv & KI-Powered**

---

## ðŸŽ¯ Ãœberblick

Die 0711 Platform hat einen **sophistizierten KI-gesteuerten Ingestion-Prozess**, der:
1. **Jedes Dateiformat** automatisch erkennt und verarbeitet
2. **Dynamisch klassifiziert** (Tax, Legal, Products, HR, etc.)
3. **Intelligent extrahiert** (strukturierte Daten â†’ SQL, Entities â†’ Graph, Text â†’ Vektor)
4. **Due Diligence** durchfÃ¼hrt (DatenqualitÃ¤t, VollstÃ¤ndigkeit, Anomalien)
5. **Custom Handlers generiert** (fÃ¼r unbekannte Formate via Claude)

**Kern**: **Claude Sonnet 4.5** analysiert und entscheidet automatisch!

---

## ðŸ—ï¸ Die 6 Intelligenz-Stufen

```
Datei hochgeladen
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STUFE 1: ADAPTIVE HANDLER GENERATION                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Unbekanntes Format (.DAT, .proprietary)?                   â”‚
â”‚  â†’ Claude analysiert Struktur                               â”‚
â”‚  â†’ Generiert Python Handler (on-the-fly!)                   â”‚
â”‚  â†’ Validiert & testet Handler                               â”‚
â”‚  â†’ Registriert fÃ¼r zukÃ¼nftige Nutzung                       â”‚
â”‚                                                             â”‚
â”‚  File: ingestion/claude_handler_generator.py                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STUFE 2: DOCUMENT CLASSIFICATION                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Zwei-stufig:                                               â”‚
â”‚  1. Rule-Based (schnell, Pattern Matching)                  â”‚
â”‚     â†’ 100+ Keywords (DE/EN) pro Kategorie                   â”‚
â”‚     â†’ Scoring-System                                        â”‚
â”‚  2. Claude Classification (wenn unsicher)                   â”‚
â”‚     â†’ Liest Filename + Content-Sample                       â”‚
â”‚     â†’ Entscheidet: tax/legal/products/hr/general            â”‚
â”‚                                                             â”‚
â”‚  Files: ingestion/classifier/document_classifier.py         â”‚
â”‚         ingestion/classifier/rules.py                       â”‚
â”‚         ingestion/classifier/prompts.py                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STUFE 3: SCHEMA ANALYSIS (Intelligente Struktur-Erkennung) â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Claude analysiert Daten-Struktur:                          â”‚
â”‚  1. Ist das strukturierte Daten? â†’ SQL-Tabellen (Delta)     â”‚
â”‚  2. Gibt es Entities? â†’ Graph-Schema (Neo4j)                â”‚
â”‚  3. Was soll durchsuchbar sein? â†’ Vector-Indices (Lance)    â”‚
â”‚                                                             â”‚
â”‚  Output: StorageStrategy {                                  â”‚
â”‚    data_type: "structured_catalog",                         â”‚
â”‚    sql_tables: [{name, columns, primary_key}],              â”‚
â”‚    graph_schema: {nodes, relationships},                    â”‚
â”‚    vector_indices: [{name, fields}]                         â”‚
â”‚  }                                                          â”‚
â”‚                                                             â”‚
â”‚  File: ingestion/analyzer/schema_analyzer.py                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STUFE 4: INTELLIGENT EXTRACTION                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Liest DEPLOYMENT.md (Customer Context):                    â”‚
â”‚  - Company: "EATON"                                         â”‚
â”‚  - Industry: "Electrical Components"                        â”‚
â”‚  - Source Format: "BMEcat 2005 XML"                         â”‚
â”‚  - Transformation Rules: {JSONPath â†’ SQL Column}            â”‚
â”‚                                                             â”‚
â”‚  Claude extrahiert mit Context:                             â”‚
â”‚  - Versteht Branchen-Spezifika                              â”‚
â”‚  - Wendet Transformation Rules an                           â”‚
â”‚  - Mapped zu Standard-Schema                                â”‚
â”‚  - Validiert DatenqualitÃ¤t                                  â”‚
â”‚                                                             â”‚
â”‚  Output: Strukturierte Records fÃ¼r Delta Tables             â”‚
â”‚                                                             â”‚
â”‚  File: ingestion/extractor/intelligent_extractor.py         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STUFE 5: ENTITY EXTRACTION (Graph Intelligence)            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Extrahiert Entities fÃ¼r Neo4j:                             â”‚
â”‚  - Companies (Lieferanten, Kunden, Partner)                 â”‚
â”‚  - Products (mit Beziehungen)                               â”‚
â”‚  - People (Ansprechpartner)                                 â”‚
â”‚  - Locations (Standorte)                                    â”‚
â”‚  - Relationships (liefert_an, arbeitet_bei, etc.)           â”‚
â”‚                                                             â”‚
â”‚  Nutzt: spaCy DE + Custom Rules                             â”‚
â”‚                                                             â”‚
â”‚  File: ingestion/processor/entity_extractor.py              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STUFE 6: DUE DILIGENCE & QUALITY CHECKS                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Claude prÃ¼ft automatisch:                                  â”‚
â”‚  âœ“ VollstÃ¤ndigkeit (alle Pflichtfelder?)                    â”‚
â”‚  âœ“ Konsistenz (Preise plausibel? Daten widerspruchsfrei?)  â”‚
â”‚  âœ“ Anomalien (Outlier, verdÃ¤chtige Werte)                   â”‚
â”‚  âœ“ Duplikate (gleiche Produkte mehrfach?)                   â”‚
â”‚  âœ“ Referenz-IntegritÃ¤t (verweisen IDs auf existierende?)    â”‚
â”‚                                                             â”‚
â”‚  Output: Data Quality Report                                â”‚
â”‚  {                                                          â”‚
â”‚    "completeness_score": 0.95,                              â”‚
â”‚    "missing_fields": ["price: 12 records"],                 â”‚
â”‚    "anomalies": ["Product X has price 0"],                  â”‚
â”‚    "duplicates": 3,                                         â”‚
â”‚    "recommendation": "Ready for production"                 â”‚
â”‚  }                                                          â”‚
â”‚                                                             â”‚
â”‚  File: ingestion/analyzer/schema_analyzer.py (validate)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Beispiel: EATON Upload

### Input
```
Dateien:
- eaton_products.xml (BMEcat 2005)
- technical_specs.pdf
- unknown_format.DAT (proprietÃ¤r!)
```

### Prozess

**1. Adaptive Handler Generation**
```
unknown_format.DAT encountered
  â†“
Claude analyzes first 4KB:
  - Encoding: ISO-8859-1
  - Structure: Tab-delimited
  - Columns: ID, Name, Price, Category
  â†“
Generates Python Handler:
  class EatonDatHandler(BaseHandler):
      def extract(self, path):
          # Parse tab-delimited
          # Return structured data
  â†“
Validates syntax (AST)
Tests on sample file
Registers: ".dat" â†’ EatonDatHandler
âœ“ Ready to process all .DAT files
```

**2. Document Classification**
```
eaton_products.xml
  â†“
Rule-Based Check:
  - Filename contains "produkt" â†’ 80% products
  - Extension .xml â†’ neutral
  - Confidence: 0.8 (above threshold)
  â†“
Classification: "products" âœ“

technical_specs.pdf
  â†“
Rule-Based uncertain (generic filename)
  â†“
Claude Classification:
  Sample: "Technical Specifications..."
  Claude: "This is a products document (technical specs)"
  â†“
Classification: "products" âœ“
```

**3. Schema Analysis**
```
eaton_products.xml analyzed
  â†“
Claude determines:
  Data Type: STRUCTURED_CATALOG
  â†“
  SQL Tables:
    - products (gtin, brand, model, price, ...)
    - suppliers (name, id, contact)
    - categories (etim_class, description)
  â†“
  Graph Schema:
    Nodes: [Product, Supplier, Category]
    Relationships: [
      (Product)-[SUPPLIED_BY]->(Supplier),
      (Product)-[IN_CATEGORY]->(Category)
    ]
  â†“
  Vector Indices:
    - product_descriptions (for search)
    - technical_specs (for RAG)
```

**4. Intelligent Extraction**
```
Reads DEPLOYMENT.md:
  Company: EATON
  Industry: Electrical Components
  Source Format: BMEcat 2005 XML
  Transformation Rules:
    - ARTICLE/ARTICLE_DETAILS/MANUFACTURER_AID â†’ sku
    - ARTICLE/ARTICLE_DETAILS/DESCRIPTION_SHORT â†’ name
    - ARTICLE_PRICE_DETAILS/ARTICLE_PRICE â†’ price
    ...
  â†“
Claude extracts with rules:
  <ARTICLE>
    <ARTICLE_DETAILS>
      <MANUFACTURER_AID>123456</MANUFACTURER_AID>
      <DESCRIPTION_SHORT>Circuit Breaker</DESCRIPTION_SHORT>
    </ARTICLE_DETAILS>
  </ARTICLE>
  â†“
  Mapped to:
  {
    "sku": "123456",
    "name": "Circuit Breaker",
    "gtin": "...",
    "price": 45.99,
    ...
  }
  â†“
Output: 669 product records (validated)
```

**5. Entity Extraction**
```
From extracted products:
  â†“
Entities found:
  - Companies: ["EATON", "Schneider Electric", "ABB"]
  - Products: 669 items
  - Categories: ["Circuit Breakers", "Contactors", ...]
  â†“
Relationships:
  - (Product ID=123)-[MANUFACTURED_BY]->(EATON)
  - (Product ID=123)-[IN_CATEGORY]->(Circuit Breakers)
  - (EATON)-[COMPETES_WITH]->(Schneider Electric)
  â†“
Neo4j Graph: 1,500 nodes, 4,500 edges
```

**6. Due Diligence**
```
Claude validates:
  âœ“ Completeness: 98% (12 products missing price)
  âœ“ Consistency: Price range â‚¬5-â‚¬5,000 (plausible)
  âš  Anomalies: 3 products with price â‚¬0 (flag for review)
  âœ“ Duplicates: None found
  âœ“ References: All category IDs valid
  â†“
Quality Score: 9.2/10
Recommendation: "Ready for production. Review 3 zero-price items."
  â†“
Report saved to lakehouse
Admin kann Due Diligence Report einsehen
```

---

## ðŸ”§ Technische Komponenten

### 1. Claude Handler Generator
**File**: `ingestion/claude_handler_generator.py`

**Macht**:
- Analysiert unbekannte Dateiformate
- Generiert Python-Code fÃ¼r Handler-Klasse
- Validiert mit AST (Syntax-Check)
- Testet Handler auf Sample-File
- Registriert fÃ¼r zukÃ¼nftige Nutzung

**Beispiel**: EATON .DAT Format
```python
# Automatisch generiert von Claude:
class EatonDatHandler(BaseHandler):
    async def extract(self, path: Path) -> Optional[str]:
        with open(path, 'r', encoding='iso-8859-1') as f:
            lines = f.readlines()

        header = lines[0].strip().split('\t')
        records = []

        for line in lines[1:]:
            values = line.strip().split('\t')
            record = dict(zip(header, values))
            records.append(record)

        return json.dumps(records)
```

### 2. Document Classifier
**File**: `ingestion/classifier/document_classifier.py`

**Strategie** (2-stufig):
```python
async def classify(file_path, content_sample):
    # Stufe 1: Rule-Based (schnell, kostenlos)
    category, confidence = rule_classifier.classify(file_path)

    if confidence >= 0.6:
        return category  # Sicher genug

    # Stufe 2: Claude Classification (genau, kostet Tokens)
    if content_sample and claude_client:
        prompt = build_classification_prompt(filename, content_sample)
        category = await claude_classify(prompt)
        return category

    # Fallback
    return "general"
```

**Kategorien**:
- `tax` - Steuer, Buchhaltung, DATEV
- `legal` - VertrÃ¤ge, Rechnungen, Compliance
- `products` - Kataloge, ETIM, Stammdaten
- `hr` - Personal, Bewerbungen, Gehaltsabrechnungen
- `general` - Alles andere

### 3. Schema Analyzer
**File**: `ingestion/analyzer/schema_analyzer.py`

**Entscheidet Storage-Strategie**:
```python
await schema_analyzer.analyze(file, content, classification)
  â†“
Returns: StorageStrategy {
    data_type: STRUCTURED_CATALOG,

    sql_tables: [
        TableSchema(
            name="products",
            columns=[
                {name: "gtin", type: "VARCHAR(14)", description: "..."},
                {name: "brand", type: "VARCHAR(100)", ...},
                {name: "price", type: "DECIMAL(10,2)", ...}
            ],
            primary_key="gtin"
        ),
        TableSchema(name="suppliers", ...)
    ],

    graph_schema: GraphSchema(
        nodes=[{type: "Product", properties: [...]}],
        relationships=[{from: "Product", to: "Supplier", type: "SUPPLIED_BY"}]
    ),

    vector_indices: [
        VectorIndex(
            name="product_search",
            fields=["name", "description", "technical_specs"]
        )
    ],

    confidence: "high"
}
```

**Claude Prompt** (vereinfacht):
```
Analyze this data structure:
File: eaton_products.xml
Sample: <ARTICLE>...</ARTICLE>

Determine:
1. Is this structured data for SQL tables?
2. What entities exist for graph database?
3. What text fields need vector indexing?

Return JSON with table schemas, graph schema, vector indices.
```

### 4. Intelligent Extractor
**File**: `ingestion/extractor/intelligent_extractor.py`

**Nutzt Deployment Context**:
```python
# Liest DEPLOYMENT.md (Customer-spezifisch)
deployment_context = {
    "company_name": "EATON",
    "industry": "Electrical Components",
    "source_format": "BMEcat 2005",
    "transformation_rules": {
        "ARTICLE/MANUFACTURER_AID": "sku",
        "ARTICLE_PRICE_DETAILS/ARTICLE_PRICE/@price_amount": "price",
        ...
    }
}

# Claude extrahiert mit Context
extracted = await intelligent_extractor.extract_to_standard_schema(
    file_content=xml_content,
    deployment_context=deployment_context,
    classification="products",
    filename="eaton_products.xml"
)

# Returns:
{
    "products": [
        {"gtin": "...", "sku": "123456", "name": "...", "price": 45.99},
        ...
    ],
    "data_quality": {
        "completeness": 0.98,
        "issues": ["12 products missing price"]
    }
}
```

**Claude Prompt** (Beispiel):
```
You are processing data for: EATON
Industry: Electrical Components

TASK: Extract structured product data from BMEcat XML.

TRANSFORMATION RULES:
- MANUFACTURER_AID â†’ sku
- DESCRIPTION_SHORT â†’ name
- ARTICLE_PRICE â†’ price
- ETIM_CLASS â†’ etim_classification

SOURCE DATA:
<ARTICLE>
  <MANUFACTURER_AID>EC-4567</MANUFACTURER_AID>
  <DESCRIPTION_SHORT>Contactor 3-pole</DESCRIPTION_SHORT>
  <ARTICLE_PRICE>89.50</ARTICLE_PRICE>
</ARTICLE>

Extract to JSON:
{
  "products": [
    {"sku": "EC-4567", "name": "Contactor 3-pole", "price": 89.50}
  ]
}
```

### 5. Entity Extractor
**File**: `ingestion/processor/entity_extractor.py`

**Extrahiert fÃ¼r Graph**:
- Companies (Named Entity Recognition)
- Products (aus strukturierten Daten)
- People (Ansprechpartner)
- Locations (Standorte, Lieferadressen)

**Beispiel**:
```
Text: "EATON liefert Schaltanlagen an Siemens in MÃ¼nchen"
  â†“
Entities:
  - Company: "EATON" (Supplier)
  - Company: "Siemens" (Customer)
  - Product: "Schaltanlagen"
  - Location: "MÃ¼nchen"
  â†“
Relationships:
  - (EATON)-[SUPPLIES]->(Siemens)
  - (Siemens)-[LOCATED_IN]->(MÃ¼nchen)
```

### 6. Ingestion Orchestrator (Koordiniert alles)
**File**: `ingestion/orchestrator.py`

**Kompletter Pipeline**:
```python
orchestrator = IngestionOrchestrator(
    lakehouse_path=Path("/data/lakehouse"),
    claude_api_key="sk-ant-...",
    embedding_model="multilingual-e5-large"
)

result = await orchestrator.ingest(
    folder_configs=[
        FolderConfig(
            path=Path("/uploads/eaton"),
            mcp_assignment="products",  # Optional hint
            recursive=True
        )
    ],
    customer_id="eaton"
)

# Pipeline lÃ¤uft:
# 1. Crawl (FileCrawler) â†’ Findet alle Dateien
# 2. Extract (mit auto-generierten Handlers)
# 3. Classify (Rule + Claude)
# 4. Analyze Schema (Claude)
# 5. Intelligent Extract (Claude mit Context)
# 6. Chunk & Embed (Embeddings-Service)
# 7. Extract Entities (spaCy + Claude)
# 8. Load to Lakehouse (Delta + Lance + Neo4j)

# Returns:
{
    "total_files": 669,
    "total_documents": 31807,
    "total_embeddings": 31807,
    "errors": [],
    "stats_by_mcp": {
        "products": 669,
        "tax": 0,
        "legal": 0
    }
}
```

---

## ðŸŽ¯ Wie es im Admin Portal funktioniert

### Aktueller Flow (bereits implementiert!)

```
Admin uploaded Dateien via UI
  â†“
POST /api/upload/files?customer_id=eaton2&selected_mcps=ctax,law,etim
  â†“
Backend (api/routes/upload.py):
  1. Files â†’ MinIO (bucket: customer-eaton2/)
  2. First upload detection â†’ Trigger Deployment
  3. Background Task startet:
  â†“
IngestionOrchestrator.ingest()
  â”œâ”€ Stage 1: Claude generiert Handler (falls nÃ¶tig)
  â”œâ”€ Stage 2: Klassifiziert Dokumente (Claude + Rules)
  â”œâ”€ Stage 3: Analysiert Schema (Claude)
  â”œâ”€ Stage 4: Extrahiert intelligent (Claude mit DEPLOYMENT.md)
  â”œâ”€ Stage 5: Extrahiert Entities (spaCy + Claude)
  â”œâ”€ Stage 6: Quality Check (Claude)
  â”œâ”€ Stage 7: Embeddings generieren (Cradle GPU)
  â””â”€ Stage 8: Load zu Lakehouse (Delta + Lance + Neo4j)
  â†“
console_builder.py builds Docker image
  â†“
eaton2-intelligence:1.0 fertig!
  â†“
Admin kann downloaden
```

---

## ðŸ¤– Claude Prompts (Beispiele)

### Classification Prompt
```
Analyze this document and classify into ONE category:

Categories:
- tax: Tax documents, DATEV, Jahresabschluss
- legal: Contracts, invoices, compliance
- products: Catalogs, ETIM, specifications
- hr: Employee records, payroll
- general: Everything else

Filename: liefervertrag_2024.pdf
Content:
"""
Liefervereinbarung zwischen EATON und Kunde X
Artikel: SchaltgerÃ¤te Typ XY...
"""

Output ONLY the category: legal
```

### Extraction Prompt
```
You are processing data for: EATON
Industry: Electrical Components

Extract product data from this BMEcat XML:
<ARTICLE>
  <MANUFACTURER_AID>EC-100</MANUFACTURER_AID>
  <DESCRIPTION_SHORT>Contactor</DESCRIPTION_SHORT>
</ARTICLE>

Map to schema:
{
  "sku": "EC-100",
  "name": "Contactor",
  ...
}
```

### Due Diligence Prompt
```
Review this extracted product data for quality:

Data: 669 products from EATON catalog

Check:
1. Completeness: Are all required fields present?
2. Consistency: Are prices/dimensions plausible?
3. Anomalies: Any outliers or suspicious values?
4. Duplicates: Same product multiple times?

Return JSON:
{
  "completeness_score": 0.95,
  "missing_fields": [...],
  "anomalies": [...],
  "recommendation": "..."
}
```

---

## ðŸ“Š Was macht das System intelligent?

### 1. **Adaptive** (lernt neue Formate)
- Erster Upload: .DAT unbekannt â†’ Claude generiert Handler
- Zweiter Upload: .DAT bekannt â†’ nutzt generierten Handler
- **Kein manuelles Coding mehr!**

### 2. **Context-Aware** (versteht Kunde)
- Liest DEPLOYMENT.md (Company, Industry, Rules)
- Wendet Customer-spezifische Transformationen an
- Versteht Branchen-Terminologie

### 3. **Multi-Strategy** (optimal & kosteneffizient)
- Rule-Based first (schnell, kostenlos)
- Claude nur wenn nÃ¶tig (genau, kostet Tokens)
- Fallbacks auf allen Ebenen

### 4. **Quality-First** (Due Diligence eingebaut)
- Automatische Validierung
- Anomalie-Erkennung
- Reports fÃ¼r Admin

### 5. **Multi-Modal Storage** (optimal fÃ¼r jeden Datentyp)
- Strukturiert â†’ Delta Lake (SQL)
- Entities â†’ Neo4j (Graph)
- Text â†’ LanceDB (Vektor-Suche)

---

## âœ… Aktueller Stand

**Wo lÃ¤uft das?**:
- âœ… **Lightnet**: 104,699 Produkte, intelligent klassifiziert & extrahiert
- âœ… **EATON**: 669 Produkte, Claude-generierte .DAT Handler
- âœ… **Partner Portal**: Nutzt diesen Flow fÃ¼r Customer Onboarding
- âœ… **Admin Portal**: Nutzt diesen Flow (via upload endpoint)

**APIs**:
- `POST /api/upload/files` - Trigger kompletten Flow
- `POST /api/upload-async/start` - Async mit Progress-Polling
- `GET /api/upload/status/{job_id}` - Progress abfragen

---

## ðŸš€ FÃ¼r neuen Kunden nutzen

**Im Admin Portal** (aktuell implementiert):
```
1. Upload Files via Drag & Drop
2. System macht automatisch:
   âœ“ Handler Generation (falls nÃ¶tig)
   âœ“ Classification (Claude + Rules)
   âœ“ Schema Analysis (Claude)
   âœ“ Intelligent Extraction (mit Context)
   âœ“ Entity Extraction (Graph)
   âœ“ Due Diligence (Quality Check)
   âœ“ Embeddings (GPU)
   âœ“ Load to Lakehouse
3. Fertig!
```

**Kein manuelles Mapping, keine Config-Files, keine Schemas definieren - Claude macht alles automatisch!** ðŸ¤–âœ¨

---

**Das ist der sophistizierte Teil den du gesucht hast!** ðŸŽ‰
