# 0711 Platform - Complete Architecture

**Per-Customer AI Brain with Continuous Learning**

---

## ğŸ§  Core Concept

Each customer gets their **own dedicated AI brain** that:
- Learns from their specific business
- Understands their data formats
- Improves with every interaction
- Never shares intelligence with other customers

---

## ğŸ“ Per-Customer Stack

### Example: EATON Deployment

```
EATON Installation (Ports 5100-5199)
â”œâ”€â”€ Mixtral-8x7B Instance (Port 5100)
â”‚   â”œâ”€â”€ Base: Mixtral-8x7B-Instruct (24GB)
â”‚   â”œâ”€â”€ EATON LoRA v1: Product data specialist (2GB)
â”‚   â”œâ”€â”€ EATON LoRA v2: German technical docs (2GB)
â”‚   â””â”€â”€ Hot-swappable <1 second
â”‚
â”œâ”€â”€ Embeddings (Port 5101)
â”‚   â””â”€â”€ multilingual-e5-large (4GB)
â”‚
â”œâ”€â”€ Customer Lakehouse
â”‚   â”œâ”€â”€ Delta Lake: Structured data tables
â”‚   â”œâ”€â”€ Lance DB: Vector embeddings
â”‚   â”œâ”€â”€ Neo4j Graph: Entity relationships
â”‚   â””â”€â”€ All isolated to EATON only
â”‚
â”œâ”€â”€ MinIO Bucket: customer-eaton
â”‚   â”œâ”€â”€ Raw files uploaded
â”‚   â”œâ”€â”€ Processed documents
â”‚   â””â”€â”€ Training data for LoRAs
â”‚
â”œâ”€â”€ Selected MCPs
â”‚   â”œâ”€â”€ ETIM Classification (Port 5122)
â”‚   â”œâ”€â”€ Product Management (Port 5123)
â”‚   â””â”€â”€ CTAX (Port 5120)
â”‚
â”œâ”€â”€ LoRA Trainer (Port 5130)
â”‚   â”œâ”€â”€ Trains from EATON interactions
â”‚   â”œâ”€â”€ Daily updates
â”‚   â””â”€â”€ Automatic deployment
â”‚
â””â”€â”€ Console UI (Port 5110)
    â””â”€â”€ EATON-branded interface
```

### Example: e-ProCat Deployment

```
e-ProCat Installation (Ports 5200-5299)
â”œâ”€â”€ Mixtral-8x7B Instance (Port 5200)
â”œâ”€â”€ Embeddings (Port 5201)
â”œâ”€â”€ Lakehouse (e-ProCat data only)
â”œâ”€â”€ MinIO: customer-eprocat
â”œâ”€â”€ MCPs: CTAX, ETIM, Tender
â”œâ”€â”€ LoRA Trainer (Port 5230)
â””â”€â”€ Console UI (Port 5210)
```

**Complete Isolation** - No data sharing between customers!

---

## ğŸ”„ Complete Data Flow

### 1. File Upload â†’ Intelligent Import

```
EATON uploads proprietary .DAT files
    â†“
MinIO: customer-eaton/raw/
    â†“
Claude Sonnet 4.5 analyzes file
    â†“
Generates Python import handler
    â†“
Validates & tests handler
    â†“
Registers handler for future .DAT files
    â†“
Extracts data â†’ Lakehouse
```

**Key Innovation**: Claude auto-generates import scripts for ANY format!

### 2. Data Ingestion â†’ RAG Pipeline

```
Files in MinIO
    â†“
Crawl & Extract (10+ built-in handlers + Claude-generated)
    â†“
Classify to MCPs (CTAX, LAW, ETIM, etc.)
    â†“
Chunk intelligently (structure-aware)
    â†“
Embed with multilingual-e5-large
    â†“
Load to Lakehouse:
    â”œâ”€â”€ Delta Lake: Structured tables
    â”œâ”€â”€ Lance: Vector search
    â””â”€â”€ Graph: Entity relationships
```

### 3. Query â†’ MCP Orchestration

```
User asks: "Show Q4 tax liability"
    â†“
Orchestrator analyzes query
    â†“
Routes to CTAX MCP
    â†“
CTAX queries lakehouse (semantic search)
    â†“
Retrieves relevant documents
    â†“
Sends to Mixtral with customer LoRA
    â†“
Mixtral generates answer
    â†“
Returns to user with sources
```

### 4. Continuous Learning Loop

```
User interaction logs
    â†“
Query + Answer + Feedback
    â†“
Training dataset accumulation
    â†“
Daily LoRA training
    â†“
New LoRA version deployed
    â†“
Mixtral gets smarter at customer's domain
    â†“
Repeat âˆ
```

---

## ğŸ—ï¸ Component Status

### âœ… Implemented
- [x] Claude Sonnet 4.5 handler generator
- [x] Complete ingestion pipeline
- [x] Delta Lake storage
- [x] Lance vector DB
- [x] MCP SDK & base classes
- [x] LoRA manager (hot-swap code)
- [x] Model manager (LRU eviction)
- [x] Onboarding UI (file upload)
- [x] Console UI
- [x] MinIO storage
- [x] File upload to MinIO

### âš ï¸ Partially Implemented
- [~] Per-customer deployment (orchestrator created, not integrated)
- [~] vLLM deployment (docker config ready, not running)
- [~] MCP implementations (CTAX, LAW exist, not deployed per customer)

### âŒ Missing
- [ ] LoRA training pipeline (continuous learning)
- [ ] Ray Serve MCP orchestration
- [ ] Per-customer docker-compose generator (created, needs integration)
- [ ] Ingestion trigger on file upload
- [ ] Self-hosted installer package
- [ ] Deployment mode selection UI

---

## ğŸ¯ Two Deployment Modes

### Mode 1: Managed (SaaS)
**You host everything:**
```
Your Infrastructure:
â”œâ”€â”€ Customer EATON
â”‚   â”œâ”€â”€ Mixtral instance (your GPU)
â”‚   â”œâ”€â”€ Lakehouse (your storage)
â”‚   â””â”€â”€ Console (your servers)
â”œâ”€â”€ Customer e-ProCat
â”‚   â””â”€â”€ (separate stack)
â””â”€â”€ ... more customers
```

**Advantages:**
- You manage updates
- Elastic scaling
- Centralized monitoring

**Customer accesses via**: https://eaton.0711.cloud

### Mode 2: Self-Hosted (On-Premise)
**Customer runs everything:**
```
EATON's Infrastructure:
â”œâ”€â”€ Download 0711 installer
â”œâ”€â”€ Run on their servers
â”œâ”€â”€ Air-gapped possible
â”œâ”€â”€ Full data sovereignty
â””â”€â”€ License key validation

Access: http://eaton-internal-server
```

**Advantages:**
- Complete data privacy
- Air-gap capable
- Regulatory compliance
- No internet dependency

**Installer**: `install-0711.sh` (to be created)

---

## ğŸ’¡ Key Innovations

### 1. Adaptive Import (Claude)
Handles **any** file format automatically:
- SAP proprietary exports
- Legacy DATEV formats
- Custom XML schemas
- Weird Excel structures
- **No developer needed!**

### 2. Personalized AI Brain (LoRA)
Each customer's Mixtral learns their:
- Industry terminology
- Business processes
- Data patterns
- Query preferences

After 1 month: EATON's Mixtral knows EATON's business better than any consultant.

### 3. Full RAG Stack
Not just vector search:
- **Structured** (Delta Lake): SQL queries on data
- **Semantic** (Lance): "Find similar contracts"
- **Graph** (Neo4j): "Who knows this client?"
- **Hybrid**: Combine all three

### 4. MCP Orchestration
AI routes queries to right specialist:
- Tax question â†’ CTAX MCP
- Contract question â†’ LAW MCP
- Product question â†’ ETIM MCP
- Complex: Multiple MCPs in sequence

---

## ğŸ“Š Resource Requirements

### Per Customer (Managed Mode)
- **GPU**: 30GB (24GB Mixtral + 4GB embeddings + 2GB LoRA)
- **RAM**: 32GB
- **Storage**: 100GB base + customer data
- **Network**: 1 Gbps

### Self-Hosted (Customer's Hardware)
- **Minimum**: 1x A100 40GB or 2x RTX 4090
- **Recommended**: 1x A100 80GB
- **CPU**: 16+ cores
- **RAM**: 64GB+
- **Storage**: 500GB+ SSD

---

## ğŸš€ Next Steps to Complete

1. **Integrate deployment orchestrator** into onboarding API
2. **Wire file upload** â†’ ingestion trigger
3. **Build LoRA training pipeline** (daily fine-tuning)
4. **Create self-hosted installer** package
5. **Add deployment mode** to onboarding UI
6. **Deploy test customer** (EATON or e-ProCat)
7. **Verify complete flow** end-to-end

---

## ğŸ“ Customer Experience

### Managed (SaaS):
1. Go to 0711.cloud/onboarding
2. Upload data (files/folders)
3. Select MCPs
4. Wait 10 minutes (deployment + ingestion)
5. Access console at eaton.0711.cloud
6. Start chatting with their AI brain

### Self-Hosted (On-Premise):
1. Download install-0711.sh
2. Run: `sudo ./install-0711.sh --license=ENTERPRISE-EATON-2025`
3. Select data folders
4. Wait 15 minutes (pulls Docker images, processes data)
5. Access at http://localhost:3000
6. Start chatting

---

**Status**: Architecture complete, core built, deployment automation next! ğŸš€
